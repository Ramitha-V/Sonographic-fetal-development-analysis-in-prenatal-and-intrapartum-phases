{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:42:37.114611Z",
     "iopub.status.busy": "2025-04-07T09:42:37.114305Z",
     "iopub.status.idle": "2025-04-07T09:42:43.744442Z",
     "shell.execute_reply": "2025-04-07T09:42:43.743783Z",
     "shell.execute_reply.started": "2025-04-07T09:42:37.114552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:42:43.745497Z",
     "iopub.status.busy": "2025-04-07T09:42:43.745157Z",
     "iopub.status.idle": "2025-04-07T09:42:43.749647Z",
     "shell.execute_reply": "2025-04-07T09:42:43.748862Z",
     "shell.execute_reply.started": "2025-04-07T09:42:43.745477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = \"/kaggle/input/fetal-brain-abnormalities\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"_classes.csv\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 2\n",
    "MODEL_SAVE_PATH = \"cbam_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:05.166097Z",
     "iopub.status.busy": "2025-04-07T09:43:05.165788Z",
     "iopub.status.idle": "2025-04-07T09:43:05.286894Z",
     "shell.execute_reply": "2025-04-07T09:43:05.286044Z",
     "shell.execute_reply.started": "2025-04-07T09:43:05.166076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load Dataset\n",
    "def load_dataset_from_folder(folder_path):\n",
    "    df = pd.read_csv(os.path.join(folder_path, \"_classes.csv\"))\n",
    "    image_paths = df['filename'].apply(lambda x: os.path.join(folder_path, x))\n",
    "    labels = df.drop(columns=['filename']).values\n",
    "    label_indices = np.argmax(labels, axis=1)\n",
    "    return image_paths, label_indices\n",
    "\n",
    "train_paths, train_labels = load_dataset_from_folder(os.path.join(BASE_DIR, \"train\"))\n",
    "val_paths, val_labels = load_dataset_from_folder(os.path.join(BASE_DIR, \"valid\"))\n",
    "test_paths, test_labels = load_dataset_from_folder(os.path.join(BASE_DIR, \"test\"))\n",
    "\n",
    "class_names = pd.read_csv(os.path.join(BASE_DIR, \"train\", \"_classes.csv\")).columns[1:].tolist()\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:11.731072Z",
     "iopub.status.busy": "2025-04-07T09:43:11.730787Z",
     "iopub.status.idle": "2025-04-07T09:43:11.735015Z",
     "shell.execute_reply": "2025-04-07T09:43:11.734103Z",
     "shell.execute_reply.started": "2025-04-07T09:43:11.731051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:24.677284Z",
     "iopub.status.busy": "2025-04-07T09:43:24.676972Z",
     "iopub.status.idle": "2025-04-07T09:43:24.682312Z",
     "shell.execute_reply": "2025-04-07T09:43:24.681416Z",
     "shell.execute_reply.started": "2025-04-07T09:43:24.677258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:38.051441Z",
     "iopub.status.busy": "2025-04-07T09:43:38.051140Z",
     "iopub.status.idle": "2025-04-07T09:43:38.057036Z",
     "shell.execute_reply": "2025-04-07T09:43:38.056235Z",
     "shell.execute_reply.started": "2025-04-07T09:43:38.051417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class FetalBrainDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Data Loaders\n",
    "train_dataset = FetalBrainDataset(train_paths, train_labels, transform=train_transform)\n",
    "val_dataset = FetalBrainDataset(val_paths, val_labels, transform=val_transform)\n",
    "test_dataset = FetalBrainDataset(test_paths, test_labels, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:45.206473Z",
     "iopub.status.busy": "2025-04-07T09:43:45.206195Z",
     "iopub.status.idle": "2025-04-07T09:43:45.263548Z",
     "shell.execute_reply": "2025-04-07T09:43:45.262895Z",
     "shell.execute_reply.started": "2025-04-07T09:43:45.206453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_sample_counts = np.bincount(train_labels)\n",
    "weights = 1. / class_sample_counts\n",
    "sample_weights = weights[train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:43:54.548091Z",
     "iopub.status.busy": "2025-04-07T09:43:54.547814Z",
     "iopub.status.idle": "2025-04-07T09:43:54.552787Z",
     "shell.execute_reply": "2025-04-07T09:43:54.551844Z",
     "shell.execute_reply.started": "2025-04-07T09:43:54.548071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:44:38.023679Z",
     "iopub.status.busy": "2025-04-07T09:44:38.023318Z",
     "iopub.status.idle": "2025-04-07T09:44:38.031502Z",
     "shell.execute_reply": "2025-04-07T09:44:38.030688Z",
     "shell.execute_reply.started": "2025-04-07T09:44:38.023648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CBAM modules\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv(x))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(channels)\n",
    "        self.spatial_attention = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.channel_attention(x)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:44:45.939000Z",
     "iopub.status.busy": "2025-04-07T09:44:45.938719Z",
     "iopub.status.idle": "2025-04-07T09:44:45.945194Z",
     "shell.execute_reply": "2025-04-07T09:44:45.944368Z",
     "shell.execute_reply.started": "2025-04-07T09:44:45.938981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ResNet50 + CBAM\n",
    "class ResNet50_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet50_CBAM, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        self.conv1 = base_model.conv1\n",
    "        self.bn1 = base_model.bn1\n",
    "        self.relu = base_model.relu\n",
    "        self.maxpool = base_model.maxpool\n",
    "\n",
    "        self.layer1 = nn.Sequential(base_model.layer1, CBAM(256))\n",
    "        self.layer2 = nn.Sequential(base_model.layer2, CBAM(512))\n",
    "        self.layer3 = nn.Sequential(base_model.layer3, CBAM(1024))\n",
    "        self.layer4 = nn.Sequential(base_model.layer4, CBAM(2048))\n",
    "\n",
    "        self.avgpool = base_model.avgpool\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:44:52.935893Z",
     "iopub.status.busy": "2025-04-07T09:44:52.935574Z",
     "iopub.status.idle": "2025-04-07T09:44:54.245406Z",
     "shell.execute_reply": "2025-04-07T09:44:54.244758Z",
     "shell.execute_reply.started": "2025-04-07T09:44:52.935870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 209MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet50_CBAM(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:45:01.260287Z",
     "iopub.status.busy": "2025-04-07T09:45:01.259999Z",
     "iopub.status.idle": "2025-04-07T09:45:01.265357Z",
     "shell.execute_reply": "2025-04-07T09:45:01.264556Z",
     "shell.execute_reply.started": "2025-04-07T09:45:01.260267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:45:31.296459Z",
     "iopub.status.busy": "2025-04-07T09:45:31.296167Z",
     "iopub.status.idle": "2025-04-07T09:45:31.304136Z",
     "shell.execute_reply": "2025-04-07T09:45:31.303197Z",
     "shell.execute_reply.started": "2025-04-07T09:45:31.296439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            correct += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_epoch_loss = val_loss / val_total\n",
    "        val_epoch_acc = val_correct / val_total\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        print(f\"           Val Loss: {val_epoch_loss:.4f} | Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "        if val_epoch_acc > best_acc:\n",
    "            best_acc = val_epoch_acc\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(\"Best model saved.\")\n",
    "\n",
    "    print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:45:38.449393Z",
     "iopub.status.busy": "2025-04-07T09:45:38.449082Z",
     "iopub.status.idle": "2025-04-07T09:54:30.175437Z",
     "shell.execute_reply": "2025-04-07T09:54:30.174461Z",
     "shell.execute_reply.started": "2025-04-07T09:45:38.449367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 2.1081 | Train Acc: 0.4810\n",
      "           Val Loss: 1.7793 | Val Acc: 0.5575\n",
      "Best model saved.\n",
      "Epoch 2 | Train Loss: 0.6943 | Train Acc: 0.8413\n",
      "           Val Loss: 0.8243 | Val Acc: 0.7644\n",
      "Best model saved.\n",
      "Epoch 3 | Train Loss: 0.2745 | Train Acc: 0.9274\n",
      "           Val Loss: 0.5567 | Val Acc: 0.8391\n",
      "Best model saved.\n",
      "Epoch 4 | Train Loss: 0.1936 | Train Acc: 0.9499\n",
      "           Val Loss: 0.2249 | Val Acc: 0.9425\n",
      "Best model saved.\n",
      "Epoch 5 | Train Loss: 0.1570 | Train Acc: 0.9556\n",
      "           Val Loss: 0.1879 | Val Acc: 0.9483\n",
      "Best model saved.\n",
      "Epoch 6 | Train Loss: 0.1208 | Train Acc: 0.9704\n",
      "           Val Loss: 0.1649 | Val Acc: 0.9598\n",
      "Best model saved.\n",
      "Epoch 7 | Train Loss: 0.1052 | Train Acc: 0.9725\n",
      "           Val Loss: 0.1813 | Val Acc: 0.9368\n",
      "Epoch 8 | Train Loss: 0.0916 | Train Acc: 0.9704\n",
      "           Val Loss: 0.0995 | Val Acc: 0.9713\n",
      "Best model saved.\n",
      "Epoch 9 | Train Loss: 0.0598 | Train Acc: 0.9866\n",
      "           Val Loss: 0.1473 | Val Acc: 0.9598\n",
      "Epoch 10 | Train Loss: 0.0644 | Train Acc: 0.9803\n",
      "           Val Loss: 0.1412 | Val Acc: 0.9655\n",
      "Epoch 11 | Train Loss: 0.0783 | Train Acc: 0.9760\n",
      "           Val Loss: 0.1723 | Val Acc: 0.9713\n",
      "Epoch 12 | Train Loss: 0.0516 | Train Acc: 0.9845\n",
      "           Val Loss: 0.1164 | Val Acc: 0.9598\n",
      "Epoch 13 | Train Loss: 0.0427 | Train Acc: 0.9873\n",
      "           Val Loss: 0.1057 | Val Acc: 0.9655\n",
      "Epoch 14 | Train Loss: 0.0250 | Train Acc: 0.9937\n",
      "           Val Loss: 0.0915 | Val Acc: 0.9828\n",
      "Best model saved.\n",
      "Epoch 15 | Train Loss: 0.0199 | Train Acc: 0.9922\n",
      "           Val Loss: 0.1158 | Val Acc: 0.9713\n",
      "Epoch 16 | Train Loss: 0.0193 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1075 | Val Acc: 0.9713\n",
      "Epoch 17 | Train Loss: 0.0231 | Train Acc: 0.9915\n",
      "           Val Loss: 0.1086 | Val Acc: 0.9713\n",
      "Epoch 18 | Train Loss: 0.0200 | Train Acc: 0.9929\n",
      "           Val Loss: 0.1018 | Val Acc: 0.9828\n",
      "Epoch 19 | Train Loss: 0.0141 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1144 | Val Acc: 0.9713\n",
      "Epoch 20 | Train Loss: 0.0137 | Train Acc: 0.9972\n",
      "           Val Loss: 0.0871 | Val Acc: 0.9713\n",
      "Epoch 21 | Train Loss: 0.0113 | Train Acc: 0.9986\n",
      "           Val Loss: 0.1149 | Val Acc: 0.9713\n",
      "Epoch 22 | Train Loss: 0.0131 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1070 | Val Acc: 0.9713\n",
      "Epoch 23 | Train Loss: 0.0152 | Train Acc: 0.9937\n",
      "           Val Loss: 0.1133 | Val Acc: 0.9713\n",
      "Epoch 24 | Train Loss: 0.0122 | Train Acc: 0.9979\n",
      "           Val Loss: 0.0981 | Val Acc: 0.9770\n",
      "Epoch 25 | Train Loss: 0.0123 | Train Acc: 0.9979\n",
      "           Val Loss: 0.1311 | Val Acc: 0.9713\n",
      "Epoch 26 | Train Loss: 0.0076 | Train Acc: 0.9986\n",
      "           Val Loss: 0.1321 | Val Acc: 0.9713\n",
      "Epoch 27 | Train Loss: 0.0081 | Train Acc: 0.9972\n",
      "           Val Loss: 0.1246 | Val Acc: 0.9713\n",
      "Epoch 28 | Train Loss: 0.0139 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1333 | Val Acc: 0.9713\n",
      "Epoch 29 | Train Loss: 0.0091 | Train Acc: 0.9979\n",
      "           Val Loss: 0.1290 | Val Acc: 0.9713\n",
      "Epoch 30 | Train Loss: 0.0101 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1279 | Val Acc: 0.9713\n",
      "Epoch 31 | Train Loss: 0.0138 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1257 | Val Acc: 0.9713\n",
      "Epoch 32 | Train Loss: 0.0105 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1250 | Val Acc: 0.9713\n",
      "Epoch 33 | Train Loss: 0.0111 | Train Acc: 0.9979\n",
      "           Val Loss: 0.1323 | Val Acc: 0.9713\n",
      "Epoch 34 | Train Loss: 0.0074 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1074 | Val Acc: 0.9828\n",
      "Epoch 35 | Train Loss: 0.0091 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1285 | Val Acc: 0.9713\n",
      "Epoch 36 | Train Loss: 0.0118 | Train Acc: 0.9944\n",
      "           Val Loss: 0.1168 | Val Acc: 0.9713\n",
      "Epoch 37 | Train Loss: 0.0143 | Train Acc: 0.9951\n",
      "           Val Loss: 0.1091 | Val Acc: 0.9828\n",
      "Epoch 38 | Train Loss: 0.0103 | Train Acc: 0.9972\n",
      "           Val Loss: 0.1195 | Val Acc: 0.9713\n",
      "Epoch 39 | Train Loss: 0.0192 | Train Acc: 0.9922\n",
      "           Val Loss: 0.1192 | Val Acc: 0.9713\n",
      "Epoch 40 | Train Loss: 0.0101 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1150 | Val Acc: 0.9713\n",
      "Epoch 41 | Train Loss: 0.0100 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1135 | Val Acc: 0.9713\n",
      "Epoch 42 | Train Loss: 0.0089 | Train Acc: 0.9972\n",
      "           Val Loss: 0.1174 | Val Acc: 0.9828\n",
      "Epoch 43 | Train Loss: 0.0095 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1278 | Val Acc: 0.9828\n",
      "Epoch 44 | Train Loss: 0.0081 | Train Acc: 0.9979\n",
      "           Val Loss: 0.1194 | Val Acc: 0.9828\n",
      "Epoch 45 | Train Loss: 0.0104 | Train Acc: 0.9965\n",
      "           Val Loss: 0.1118 | Val Acc: 0.9828\n",
      "Epoch 46 | Train Loss: 0.0139 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1123 | Val Acc: 0.9713\n",
      "Epoch 47 | Train Loss: 0.0100 | Train Acc: 0.9979\n",
      "           Val Loss: 0.1031 | Val Acc: 0.9828\n",
      "Epoch 48 | Train Loss: 0.0132 | Train Acc: 0.9958\n",
      "           Val Loss: 0.1270 | Val Acc: 0.9713\n",
      "Epoch 49 | Train Loss: 0.0115 | Train Acc: 0.9944\n",
      "           Val Loss: 0.1243 | Val Acc: 0.9713\n",
      "Epoch 50 | Train Loss: 0.0154 | Train Acc: 0.9944\n",
      "           Val Loss: 0.1113 | Val Acc: 0.9713\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:54:30.176998Z",
     "iopub.status.busy": "2025-04-07T09:54:30.176731Z",
     "iopub.status.idle": "2025-04-07T09:54:30.312234Z",
     "shell.execute_reply": "2025-04-07T09:54:30.311385Z",
     "shell.execute_reply.started": "2025-04-07T09:54:30.176976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-17fc45edd0ef>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet50_CBAM(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): CBAM(\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): CBAM(\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): CBAM(\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): CBAM(\n",
       "      (channel_attention): ChannelAttention(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (spatial_attention): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T09:54:30.313736Z",
     "iopub.status.busy": "2025-04-07T09:54:30.313456Z",
     "iopub.status.idle": "2025-04-07T09:54:32.014492Z",
     "shell.execute_reply": "2025-04-07T09:54:32.013464Z",
     "shell.execute_reply.started": "2025-04-07T09:54:30.313715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      " anold-chiari-malformation       1.00      1.00      1.00         3\n",
      "            arachnoid-cyst       0.93      1.00      0.96        13\n",
      "     cerebellah-hypoplasia       0.79      0.94      0.86        16\n",
      "             colphocephaly       0.90      0.82      0.86        11\n",
      "             encephalocele       1.00      1.00      1.00        15\n",
      "         holoprosencephaly       1.00      1.00      1.00         4\n",
      "             hydracenphaly       1.00      1.00      1.00         2\n",
      "    intracranial-hemorrdge       1.00      0.88      0.93         8\n",
      "        intracranial-tumor       0.00      0.00      0.00         0\n",
      "                   m-magna       1.00      1.00      1.00         4\n",
      "     mild-ventriculomegaly       1.00      1.00      1.00        24\n",
      " moderate-ventriculomegaly       0.88      0.85      0.86        26\n",
      "                    normal       1.00      0.96      0.98        24\n",
      "              polencephaly       1.00      1.00      1.00         7\n",
      "   severe-ventriculomegaly       1.00      1.00      1.00        19\n",
      "             vein-of-galen       0.00      0.00      0.00         0\n",
      "\n",
      "                 micro avg       0.95      0.95      0.95       176\n",
      "                 macro avg       0.84      0.84      0.84       176\n",
      "              weighted avg       0.95      0.95      0.95       176\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 15  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  9  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  7  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0]\n",
      " [ 0  0  4  0  0  0  0  0  0  0  0 22  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0 23  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader, set_name=\"Test\"):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(f\"\\n{set_name} Set Evaluation:\")\n",
    "    labels_list = list(range(len(class_names)))\n",
    "    print(classification_report(y_true, y_pred, labels=labels_list, target_names=class_names, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=labels_list))\n",
    "\n",
    "# Run evaluation\n",
    "evaluate(model, test_loader, set_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-import necessary libraries after code execution state reset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "metrics = ['Precision', 'Recall', 'F1-score', 'Accuracy']\n",
    "scores = [0.84, 0.84, 0.84, 0.95]\n",
    "colors = ['#c6dbef', '#9ecae1', '#6baed6', '#2171b5']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics, scores, color=colors)\n",
    "\n",
    "# Make text bold\n",
    "plt.title('Classification Evaluation Metrics', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Score', fontsize=14, fontweight='bold')\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add data labels with bold font\n",
    "for bar, score in zip(bars, scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,\n",
    "             f'{score:.2f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6946797,
     "sourceId": 11137406,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
